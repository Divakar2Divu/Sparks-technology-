# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

# Import the required libraries
from pyspark import SparkContext, SparkConf

# Step 1: Create a Spark Configuration and Spark Context
conf = SparkConf().setAppName("SparkBasics").setMaster("local[*]")
sc = SparkContext(conf=conf)

# Step 2: Create an RDD from a list
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Step 3: Perform operations on the RDD
# Example: Multiply each element by 2
mapped_rdd = rdd.map(lambda x: x * 2)

# Collect the result
result = mapped_rdd.collect()

# Step 4: Print the result
print("Original Data:", data)
print("Transformed Data (multiplied by 2):", result)

# Stop the SparkContext
sc.stop()

